{
 "cells": [
  {
   "cell_type": "raw",
   "id": "0",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: Review of Neural Networks\n",
    "author: Mark Fuge\n",
    "date: 'October 5 2025'\n",
    "format:\n",
    "    html:\n",
    "        code-fold: true\n",
    "        code-summary: \"Show Code\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "This notebook reviews some basic notation and concepts related to neural networks. It will skip many details that would have been covered in your earlier Stochastics and Machine Learning course, but will set a basis for us jumping into more advanced topics in a few chapters.\n",
    "\n",
    "Before we get started with PyTorch code, I encourage you first to interactive with the ConvNetJS demo, specifically the [interactive 1D Regression](https://cs.stanford.edu/people/karpathy/convnetjs/demo/regression.html) where you can toogle on and off the different layers and plotting functions, as well as the [2D Classification demo](https://cs.stanford.edu/people/karpathy/convnetjs/demo/classify2d.html) to see how a neural network is just performing a series of feature transformations that ultimately lead to a linear classification boundary. These demos help build a good intuition for what is going on before we move onto more obtuse PyTorch code.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Example of PyTorch SGD for Linear Regression and a Simple Feed-Forward Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 30\n",
    "\n",
    "# True Function we want to estimate\n",
    "def true_func(X): return np.cos(1.5 * np.pi * X)\n",
    "\n",
    "# Noisy Samples from the true function\n",
    "X = np.sort(2*np.random.rand(n_samples)-1)\n",
    "y = true_func(X) + np.random.randn(n_samples) * 0.1\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "# Plot the true function:\n",
    "X_plot = np.linspace(-1.5, 1.5, 100)\n",
    "plt.plot(X_plot, true_func(X_plot), '--',label=\"True function\")\n",
    "# Plot the data samples\n",
    "plt.scatter(X,y, label=\"Samples\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.4, random_state=0)\n",
    "plt.figure(figsize=(7,7))\n",
    "# Plot the data samples\n",
    "plt.scatter(X_train,y_train, label=\"Train\", c='Blue', s=20, edgecolors='none')\n",
    "plt.scatter(X_test,y_test, label=\"Test\", c='Red', s=50, edgecolors='none')\n",
    "#plt.plot(X_plot, true_func(X_plot), 'g--',label=\"True function\")\n",
    "plt.legend(loc=\"best\")\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data into a shape and data-type that PyTorch likes\n",
    "X_train = X_train.reshape(-1,1).astype(np.float32)\n",
    "y_train = y_train.reshape(-1,1).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: false\n",
    "input_size  = 1\n",
    "output_size = 1\n",
    "# Linear regression model\n",
    "model = nn.Linear(input_size, output_size)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "learning_rate = 0.1 # alpha\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: false\n",
    "# Train the model\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    # Convert numpy arrays to torch tensors\n",
    "    inputs = torch.from_numpy(X_train)\n",
    "    targets = torch.from_numpy(y_train)\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, targets)\n",
    "    \n",
    "    # Backward and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch+1) % 20 == 0:\n",
    "        print ('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the graph\n",
    "plt.figure()\n",
    "plt.plot(X_train, y_train, 'ro', label='Data')\n",
    "#predicted = model(torch.from_numpy(X_train)).detach().numpy()\n",
    "#plt.plot(X_train, predicted, 'b+',label='Predictions')\n",
    "predicted = model(torch.from_numpy(X_plot.reshape(-1,1).astype(np.float32))).detach().numpy()\n",
    "plt.plot(X_plot, predicted, 'b', label='Prediction')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### Neural Network Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "#### Example of Defining a Network via the full Module class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: false\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(Net, self).__init__()  \n",
    "        # Fully-Connected Layer: 1 (input data) -> 5 (hidden node)\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)  \n",
    "        \n",
    "        # Non-Linear Layer\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        # You can try other kinds as well\n",
    "        # self.relu = nn.ReLU()\n",
    "        # self.elu = nn.ELU()\n",
    "        \n",
    "        \n",
    "        # Fully-Connected Layer: 5 (hidden node) -> 1 (output)\n",
    "        self.fc2 = nn.Linear(hidden_size, 1) \n",
    "    \n",
    "    # Forward pass builds the model prediction from the inputs\n",
    "    def forward(self, x):                              \n",
    "        out = self.fc1(x)\n",
    "        out = self.sigmoid(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "    \n",
    "# Build the network -- is it not trained yet\n",
    "model = Net(input_size=1, hidden_size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "#### Example of building a model using the `Sequential` helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size=1\n",
    "hidden_size=4\n",
    "model = nn.Sequential(\n",
    "          nn.Linear(input_size, hidden_size),\n",
    "          nn.Sigmoid(),\n",
    "          nn.Linear(hidden_size, hidden_size),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(hidden_size, 1)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "#### Example using Python list expansions to help build deeper networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size=1\n",
    "hidden_size=7\n",
    "num_hidden_layers = 3\n",
    "activation = nn.ReLU\n",
    "\n",
    "input_layer = [nn.Linear(input_size, hidden_size),\n",
    "                activation()]\n",
    "hidden_layers = num_hidden_layers*[nn.Linear(hidden_size, hidden_size), \n",
    "                                   activation()]\n",
    "output_layer = [ nn.Linear(hidden_size, 1) ] \n",
    "\n",
    "# Stack them all together\n",
    "layers = input_layer + hidden_layers + output_layer\n",
    "\n",
    "print(layers)\n",
    "\n",
    "# Use the * operator to \"expand\" or \"unpack\" the list\n",
    "model = nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "### Now let's do the actual training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: false\n",
    "# What Loss function should we use? MSE!\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# What Optimization procedure should we use?\n",
    "\n",
    "##### Change these and let's see how it affects the model fit #################\n",
    "learning_rate = 0.05\n",
    "weight_decay = 0.0\n",
    "##########################\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: false\n",
    "### Train the model\n",
    "\n",
    "# Convert numpy arrays to torch tensors\n",
    "inputs = torch.from_numpy(X_train)\n",
    "targets = torch.from_numpy(y_train)\n",
    "\n",
    "num_epochs = 5000\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    ## Do Forward pass\n",
    "    # Make predictions\n",
    "    outputs = model(inputs)\n",
    "    # Compute the loss function\n",
    "    loss = criterion(outputs, targets)\n",
    "    \n",
    "    ## Update the model\n",
    "    # Reset the optimizer gradients\n",
    "    optimizer.zero_grad()\n",
    "    # Compute the gradient of the loss function\n",
    "    loss.backward()\n",
    "    # Do an optimization step\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Print the loss\n",
    "    if (epoch+1) % 200 == 0:\n",
    "        print ('Epoch [{:4}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "Now let's plot the prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the graph\n",
    "plt.figure()\n",
    "plt.plot(X_train, y_train, 'ro', label='Data')\n",
    "predicted = model(torch.from_numpy(X_plot.reshape(-1,1).astype(np.float32))).detach().numpy()\n",
    "plt.plot(X_plot, predicted, 'b', label='Prediction')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "::: {.callout-tip appearance=\"default\"}\n",
    "### Experiment: Effect of Regularization on Simple Toy Regression Problem\n",
    "Revisit the above regression code and experiment with the weight decay parameter in the Adam optimizer. How does this affect the learned function? Why do you think this is?:\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "You can also play around with different activation functions, e.g., `nn.ReLU()`, `nn.Sigmoid()`, `nn.Tanh()`, etc., and the below plot pulls out several options from PyTorch for you to visualize the activation functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common activation functions from PyTorch:\n",
    "activations = {\n",
    "    'Identity': nn.Identity(),\n",
    "    'ReLU': nn.ReLU(),\n",
    "    'Sigmoid': nn.Sigmoid(),\n",
    "    'Tanh': nn.Tanh(),\n",
    "    'LeakyReLU': nn.LeakyReLU(),\n",
    "    'ELU': nn.ELU(),\n",
    "    'GELU': nn.GELU(),\n",
    "    'SiLU': nn.SiLU(),  # also known as Swish\n",
    "    'Softplus': nn.Softplus(),\n",
    "    'Softsign': nn.Softsign(),\n",
    "    'Hardtanh': nn.Hardtanh(),\n",
    "    'PReLU': nn.PReLU(),\n",
    "    'CELU': nn.CELU(),\n",
    "    'SELU': nn.SELU(),\n",
    "    'Mish': nn.Mish()\n",
    "}\n",
    "x = torch.linspace(-3, 3, 100)\n",
    "n = len(activations)\n",
    "ncols = 4\n",
    "nrows = int(np.ceil(n/ncols))\n",
    "plt.figure(figsize=(15,10))\n",
    "for i, (name, activation) in enumerate(activations.items()):\n",
    "    plt.subplot(nrows, ncols, i+1)\n",
    "    plt.plot(x.numpy(), activation(x).detach().numpy())\n",
    "    plt.ylim([-1.5, 3])\n",
    "    plt.title(name)\n",
    "    plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.suptitle(\"Common Neural Network Activation Functions\", y=1.02, fontsize=16)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "## Unsupervised Learning using Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "For this demonstration, we will construct what is fundamentally a 1D function (t) but then embed it in a higher-dimensional space (3D) using a non-linear transformation. This will allow us to compare what a linear method (PCA) can do versus a non-linear method (Autoencoder), on a simple example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: false\n",
    "# First we create a simple line (t)\n",
    "t = np.linspace(-1,1,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: false\n",
    "# Now let's make it 3D and add some (optional) noise\n",
    "noise_level = 0.01\n",
    "# You can try out different functions below by uncommenting/commenting them\n",
    "#X = np.vstack([t,1*t**2,-1*t**3, 0.4*t**5,t**2-t**3,-0.4*t**4]).T\n",
    "#X = np.vstack([2*np.sin(3*t),1*t**2,-1*t**3, 2*np.sin(6*t+1)-t**3,2*np.cos(3*t)]).T\n",
    "X = np.vstack([np.sin(2*t),1*t**2,1*np.cos(5*t)]).T + noise_level*np.random.randn(len(t),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.scatter(X[:,0], X[:,1], X[:,2])\n",
    "ax.set_xlabel('$X_0$')\n",
    "ax.set_ylabel('$X_1$')\n",
    "ax.set_zlabel('$X_2$')\n",
    "ax.elev=45\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "We can see that it results in 100 points each of which has three dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: false\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "We can attempt to reduce the dimensionality of this data using PCA, but as we can already see from the 3D plot, the data is not linearly embedded in 3D space, so PCA will not be able to find a good low-dimensional representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: false\n",
    "pca = PCA(3)\n",
    "Z_PCA =pca.fit_transform(X)\n",
    "plt.figure()\n",
    "plt.scatter(Z_PCA[:,0],Z_PCA[:,1],s=15)\n",
    "plt.xlabel('PCA Dim 1')\n",
    "plt.ylabel('PCA Dim 2')\n",
    "plt.title('PCA Projection on the first two principal components')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "And we can also see this reflected in the explained variance, which shows that we need all three original dimensions to explain the variance in the data, even though we know that the data fundamentally lies on a 1D manifold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(pca.explained_variance_)\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Explained Variance')\n",
    "plt.title('PCA Explained Variance')\n",
    "plt.xticks([0,1,2])\n",
    "plt.ylim(0,1.1*max(pca.explained_variance_))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "We can see below what happens if we try to truncate PCA to only two dimensions and then reconstruct back to 3D space. The reconstruction is not very good, as expected, and what do you notice about the shape of the reconstructed data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "pca_2d = PCA(2)\n",
    "Z_PCA = pca_2d.fit_transform(X)\n",
    "X_PCA= pca_2d.inverse_transform(Z_PCA)\n",
    "ax.scatter(X[:,0], X[:,1], X[:,2],alpha=0.5)\n",
    "ax.scatter(X_PCA[:,0], X_PCA[:,1], X_PCA[:,2])\n",
    "\n",
    "ax.set_xlabel('$X_0$')\n",
    "ax.set_ylabel('$X_1$')\n",
    "ax.set_zlabel('$X_2$')\n",
    "ax.elev=35\n",
    "ax.azim=10\n",
    "plt.title(\"PCA Reconstruction with only two components\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "Now let's see how this works using an autoencoder. We will use a very simple architecture with just one hidden layer in the encoder and one hidden layer in the decoder, and we will use 1D latent space (since we know that the data is fundamentally 1D). You will have the option in the below code to change the number of hidden units in the encoder and decoder, as well as the number of latent dimensions, and see how this affects the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: false\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, num_input, num_latent,num_hidden):\n",
    "        super().__init__()\n",
    "        self.num_input  = num_input\n",
    "        self.num_latent = num_latent\n",
    "        self.num_hidden = num_hidden\n",
    "        \n",
    "        # I encourage you to modify the architecture here by adding more layers or changing activation functions, if you wish\n",
    "        self.encode = nn.Sequential(\n",
    "            nn.Linear(self.num_input, self.num_hidden),\n",
    "            nn.ReLU(),\n",
    "            #nn.Linear(self.num_hidden, self.num_hidden),\n",
    "            #nn.ReLU(),\n",
    "            nn.Linear(self.num_hidden, self.num_latent),\n",
    "        )\n",
    "        \n",
    "    def forward(self, X):\n",
    "        encoded = self.encode(X)\n",
    "        return encoded\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, num_input, num_latent,num_hidden):\n",
    "        super().__init__()\n",
    "        self.num_input  = num_input\n",
    "        self.num_latent = num_latent\n",
    "        self.num_hidden = num_hidden\n",
    "        \n",
    "        self.decode = nn.Sequential(\n",
    "            nn.Linear(self.num_latent, self.num_hidden),\n",
    "            nn.ReLU(),\n",
    "            #nn.Linear(self.num_hidden, self.num_hidden),\n",
    "            #nn.ReLU(),\n",
    "            nn.Linear(self.num_hidden, self.num_input)\n",
    "        )\n",
    "        \n",
    "    def forward(self, Z):\n",
    "        decoded = self.decode(Z)\n",
    "        return decoded\n",
    "    \n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, num_input,num_latent,num_hidden):\n",
    "        super().__init__()\n",
    "        self.num_input  = num_input\n",
    "        self.num_latent = num_latent\n",
    "        self.num_hidden = num_hidden\n",
    "        \n",
    "        self.encoder = Encoder(num_input  = self.num_input,\n",
    "                               num_latent = self.num_latent,\n",
    "                               num_hidden = self.num_hidden)\n",
    "        self.decoder = Decoder(num_input  = self.num_input,\n",
    "                               num_latent = self.num_latent,\n",
    "                               num_hidden = self.num_hidden)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        encoded = self.encoder(X)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded, encoded  # <- return a tuple of two values\n",
    "    \n",
    "    def transform(self,X):\n",
    "        '''Take X and encode to latent space'''\n",
    "        return self.encoder(X)\n",
    "    \n",
    "    def inverse_transform(self,Z):\n",
    "        '''Take Z and decode to X space'''\n",
    "        return self.decoder(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: false\n",
    "# Here we can set some parameters for the autoencoder that we are about to train\n",
    "# What happens if you change them?\n",
    "# e.g., increase/decrease num_latent, num_hidden, learning rate, weight decay\n",
    "num_points, D_orig = X.shape\n",
    "num_latent = 3\n",
    "num_hidden = 5\n",
    "model = AutoEncoder(D_orig,num_latent,num_hidden)\n",
    "# Create the optimizer object:\n",
    "# Adam optimizer with learning rate and weight decay\n",
    "# I encourage you to try out different learning rates and weight decays and\n",
    "# observe their effect on the model\n",
    "optimizer = optim.AdamW(model.parameters(), \n",
    "                        lr=1e-3, \n",
    "                        weight_decay=1e-2)\n",
    "# Add a mean-squared error loss\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: false\n",
    "X_torch = torch.from_numpy(X)\n",
    "X_torch = X_torch.float()\n",
    "\n",
    "# Depending on the model architecture you use, you may need to increase or decrease this to get good training\n",
    "epochs=10000\n",
    "for epoch in range(epochs):\n",
    "    loss = 0\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # compute reconstructions\n",
    "    decoded, encoded = model(X_torch)\n",
    "\n",
    "    # compute training reconstruction loss\n",
    "    train_loss = criterion(decoded, X_torch)\n",
    "            \n",
    "    # Total Loss\n",
    "    loss = train_loss \n",
    "    \n",
    "    # compute accumulated gradients\n",
    "    loss.backward()\n",
    "\n",
    "    # perform parameter update based on current gradients\n",
    "    optimizer.step()\n",
    "\n",
    "    # display the epoch training loss\n",
    "    if epoch%500==0:\n",
    "        print(\"epoch : {}/{}, loss = {:.6f}\".format(epoch + 1, epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "Now that the model is trained, we can put the data through the encoder and decoder to pull out both the encoded (i.e., latent) representation of each point, as well as the decoded (i.e., reconstructed) version of each point, and visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|code-fold: false\n",
    "decoded, encoded = model(X_torch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "First, let's take a look at the reconstructed data in the original 3D space, compared to the original data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "X_P = decoded.detach().numpy()\n",
    "\n",
    "ax.scatter(X[:,0], X[:,1], X[:,2],alpha=0.5)\n",
    "ax.scatter(X_P[:,0], X_P[:,1], X_P[:,2])\n",
    "ax.set_xlabel('$X_0$')\n",
    "ax.set_ylabel('$X_1$')\n",
    "ax.set_zlabel('$X_2$')\n",
    "ax.elev=25\n",
    "ax.azim=10\n",
    "plt.legend(['Original Data','Reconstructed Data'])\n",
    "plt.title(\"AE Reconstruction\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "Let's see how the encoded (i.e., latent) points actually look in Z space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = encoded.cpu().detach().numpy()\n",
    "# Only works if num_latent >=2\n",
    "if num_latent>=2:\n",
    "    plt.figure()\n",
    "    plt.scatter(Z[:,0],Z[:,1])\n",
    "    plt.xlabel('z1')\n",
    "    plt.ylabel('z2')\n",
    "    plt.title('Latent Space Representation of the autoencoder')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(Z[:,0],marker='+')\n",
    "plt.xlabel('index')\n",
    "plt.ylabel('$z_0$')\n",
    "plt.title('Latent Dimension 0 values for each data point')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {},
   "source": [
    "We can also look at a pairplot of the points in the latent space to get a sense of how the different dimensions correlate with each other:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(Z, columns=[f'z{i}' for i in range(Z.shape[1])])\n",
    "plt.figure()\n",
    "sns.pairplot(df)\n",
    "plt.suptitle('Latent Space Pairplot', y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {},
   "source": [
    "::: {.callout-tip appearance=\"default\"}\n",
    "### Experiment: Effect on Autoencoder Architecture on Reconstruction Accuracy and Latent Space Behavior \n",
    "Revisit the above autoencoder code and experiment by changing the number of hidden units, the bottleneck (latent) dimension, and the number of layers in the encoder and decoder. How do these changes affect the reconstruction accuracy and the behavior of the learned latent space? Consider some of the below questions:\n",
    "\n",
    "- We know that the data is fundamentally 1D, but why does setting the autoencoder latent dimension to 1 not work well? Why might it be useful to have a latent dimension larger than the true dimensionality of the data for this type of model?\n",
    "- What happens if you set the latent dimension to be three or larger? Why do you think this happens? What have we given up by doing this?\n",
    "- As you increase or decrease the number of hidden units in Autoencoder, how does this affect the reconstruction accuracy? Why do you think this is? Consider in particular the case where the number of hidden units is one or two.\n",
    "- Unlike in PCA, when we re-run the autoencoder training, we get different results each time. Why do you think this is?\n",
    "- Unlike PCA, the autoencoder does not guarantee that the latent dimensions are orthogonal or ordered by importance (e.g., $z_0$ being more important than $z_1$, etc.). Do you see any evidence of this in the learned latent space? Why do you think this is?\n",
    "- The Autoencoder used a ReLU activation function in the hidden layers. How does this manifest in the way that the network reconstructs the data? (Note, this may only be visible if you set the latent dimension to 1 and the number of hidden units to a small number, e.g., 2 or 3).\n",
    "- We can see that when we set the latent dimension to two or greater, the autoencoder can reconstruct the data well, but it is not capturing the intrinsic dimensionality of the data. One way we might do this is by adding L1 regularization to the latent space coordinates, which is commented out in the code above. Try adding in this regularization. Does it fix the problem?\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53",
   "metadata": {},
   "source": [
    "## Least Volume Regularization\n",
    "\n",
    "One of the problems that we saw in Autoencoders is that the latent space does not have any particular structure, and in particular, it is not guaranteed to be ordered, in the same sense as PCA. It was also difficult for us to determine the exact \"size\" of the latent dimension, since, as we saw, setting the latent dimension to 1 did not work well, even though we knew that the data was fundamentally 1D, due to training variability and the fact that the autoencoder could get trapped in local minima. One possible solution to this is to add a regularization term that encourages the latent space to be small in some sense. One such regularization is called [Least Volume Regularization](https://arxiv.org/abs/2404.17773), which encourages the latent space to have a small volume by penalizing the volume of the encoded points in the latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "class _Combo(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "\n",
    "class LinearCombo(_Combo):\n",
    "    def __init__(self, in_features, out_features, activation=nn.LeakyReLU(0.2)):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(in_features, out_features),\n",
    "            activation\n",
    "        )\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    \"\"\"Regular fully connected network generating features.\n",
    "\n",
    "    Args:\n",
    "        in_features: The number of input features.\n",
    "        out_feature: The number of output features.\n",
    "        layer_width: The widths of the hidden layers.\n",
    "        combo: The layer combination to be stacked up.\n",
    "\n",
    "    Shape:\n",
    "        - Input: `(N, H_in)` where H_in = in_features.\n",
    "        - Output: `(N, H_out)` where H_out = out_features.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, in_features: int, out_features:int, layer_width: list,\n",
    "        combo = LinearCombo\n",
    "        ):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.layer_width = list(layer_width)\n",
    "        self.model = self._build_model(combo)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "\n",
    "    def _build_model(self, combo):\n",
    "        model = nn.Sequential()\n",
    "        idx = -1\n",
    "        for idx, (in_ftr, out_ftr) in enumerate(self.layer_sizes[:-1]):\n",
    "            model.add_module(str(idx), combo(in_ftr, out_ftr))\n",
    "        model.add_module(str(idx+1), nn.Linear(*self.layer_sizes[-1])) # type:ignore\n",
    "        return model\n",
    "\n",
    "    @property\n",
    "    def layer_sizes(self):\n",
    "        return list(zip([self.in_features] + self.layer_width,\n",
    "        self.layer_width + [self.out_features]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: false\n",
    "ambient_dim = X.shape[1]\n",
    "\n",
    "# Change the below latent dimension to see what happens to the embedded points\n",
    "latent_dim = 3\n",
    "\n",
    "width = ambient_dim * 16\n",
    "encoder = MLP(ambient_dim, latent_dim, [width] * 4)\n",
    "decoder = MLP(latent_dim, ambient_dim, [width] * 4)\n",
    "\n",
    "opt = torch.optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: false\n",
    "# Set X to a torch tensor:\n",
    "X_torch = torch.from_numpy(X).float()\n",
    "\n",
    "for i in range(5000):\n",
    "    opt.zero_grad()\n",
    "    z = encoder(X_torch)\n",
    "    rec_loss = F.mse_loss(decoder(z), X_torch)\n",
    "    loss = rec_loss\n",
    "    # If you want, you can even add an L1 penalty on the latent space\n",
    "    # to try to encourage sparsity by uncommenting the line below:\n",
    "    #loss += 1e-3 * torch.mean(torch.abs(z))\n",
    "\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    if (i+1) % 100 == 0:\n",
    "        print(f'Epoch {i:4}: rec = {rec_loss:.5g}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57",
   "metadata": {},
   "source": [
    "Now that the autoencoder has been trained, let's take a look at the standard deviation of the embedded points (i.e., in $z$). We can sort the latent dimensions according to which dimensions have the highest standard deviation in Z."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.eval()\n",
    "decoder.eval()\n",
    "\n",
    "# Embed the data into Z using the trained encoder\n",
    "with torch.no_grad():\n",
    "    z = encoder(X_torch)\n",
    "# Now let's sort the latent codes by which ones have the\n",
    "# largest standard deviation in Z:\n",
    "idx = z.std(0).argsort(descending=True)\n",
    "\n",
    "plt.figure()\n",
    "plt.bar(np.arange(z.std(0).size(-1)), z.std(0)[idx])\n",
    "plt.title('latent STDs (autoencoder)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59",
   "metadata": {},
   "source": [
    "As with before, we can plot some of the data points in Z space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(z[:, idx[0]].cpu().detach().numpy(), z[:, idx[1]].cpu().detach().numpy(), s=10)\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.xlabel('$z_0$')\n",
    "plt.ylabel('$z_1$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61",
   "metadata": {},
   "source": [
    "We can also plot the covariance among the latent codes of the embedded data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = z.T[idx].cov().detach().cpu().numpy()\n",
    "plt.figure()\n",
    "plt.matshow(cov, cmap='Reds')\n",
    "for (i, j), var in np.ndenumerate(cov):\n",
    "    plt.gca().text(j, i, '{:.3e}'.format(var), ha='center', va='center')\n",
    "plt.title('Latent Covariance Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63",
   "metadata": {},
   "source": [
    "We can also get a general idea about how well we are reconstructing the original data by comparing the ground truth values versus predicted (i.e., encoded then decoded) data points -- this is often called a parity plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = decoder(z).detach()\n",
    "\n",
    "for i in range(X_torch.size(-1)):\n",
    "    plt.figure(figsize=(3,3))\n",
    "    plt.scatter(X[:, i], X_[:, i], s=3)\n",
    "    plt.gca().set_aspect('equal')\n",
    "    plt.xlabel('groundtruth')\n",
    "    plt.ylabel('reconstruction')\n",
    "    plt.title('$x_{}$'.format(i))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65",
   "metadata": {},
   "source": [
    "Lastly, we can visualize a pairplot of the latent space to see how the different dimensions correlate with each other:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(z.cpu().detach().numpy(), columns=[f'z{i}' for i in range(z.shape[1])])\n",
    "plt.figure()\n",
    "sns.pairplot(df)\n",
    "plt.suptitle('Latent Space Pairplot', y=1.02)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67",
   "metadata": {},
   "source": [
    "## How might we select the right order in an Autoencoder? Building the case for Least Volume Analysis (LVA)\n",
    "\n",
    "Our explorations above exposed both the advantages and disadvantages of using non-linear maps to attempt to embed and capture the underlying distribution and topology of the data.\n",
    "\n",
    "Below we describe the basic principle of \"Least Volume\" regularization in Autoencoders and demonstrate how it can be useful in providing automated order selection in over-parameterized Autoencoders. It can allow us to capture relevant topological structure, but with minimal dimension.\n",
    "\n",
    "![](https://arxiv.org/html/2404.17773v1/x1.png)\n",
    "\n",
    "Image above from: Qiuyi Chen and Mark Fuge, [\"Least Volume Analysis\"](https://arxiv.org/abs/2404.17773)\n",
    "\n",
    "\n",
    "In general, the idea behind least volume is that we want to encourage the latent space to take up as little volume as possible, while still being able to reconstruct the data well. This can be achieved by adding a regularization term to the loss function that penalizes the volume of the latent space. A simple way to do this is to penalize the geometric mean of the standard deviation of the latent dimensions, which encourages the latent space to be small in all dimensions. Specifically, we can minimize the product of all elements of the latent code's standard deviation vector $\\prod \\sigma$, which is equivalent to minimizing the exponential of the mean of the log of the standard deviation vector:\n",
    "\n",
    "`vol_loss = torch.exp(torch.log(z.std(0) + η).mean())`\n",
    "\n",
    "We add a small constant `η` to avoid numerical issues when any one of the standard deviation's in any dimension approaches zero -- that is when the autoencoder eliminates a dimension, and thus $\\prod \\sigma$ would have a zero in the product. This loss term can be added to the reconstruction loss, weighted by a hyperparameter `λ`, to form the total loss.\n",
    "\n",
    "In principle, while this loss can encourage the latent space to reduce its volume, there is one catch: the autoencoder could simply scale up the weights in the encoder and decoder to make the latent space arbitrarily small, while still being able to reconstruct the data well. To prevent this, we have to prevent the decoder from being able to arbitrarily increase its weights, and one easy way to enforce this is through *spectral normalization* on the weights of the decoder, which constrains the Lipschitz constant of the decoder to be at most 1. By preventing the decoder from scaling up its weights too much, and the encoder cannot easily defeat the volume penalty by isotropically shrinking the weights, and thus the only way to achieve a good volume penalty is to actually reduce dimensions.\n",
    "\n",
    "Fun Fact: It turns out that in the case of an Autoencoder that only uses Linear layers, and with no activation functions, the least volume penalty is equivalent to PCA. That is, PCA can be seen as a special case of Least Volume Autoencoder. For more details on the mathematical proof, see [Proposition 15](https://arxiv.org/html/2404.17773v2#Thmtheorem15) in the original paper.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68",
   "metadata": {},
   "source": [
    "Below code implements the spectral normalized decoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: false\n",
    "from torch.nn.utils.parametrizations import spectral_norm\n",
    "\n",
    "class SNLinearCombo(_Combo):\n",
    "    def __init__(self, in_features, out_features, activation=nn.LeakyReLU(0.2)):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            spectral_norm(nn.Linear(in_features, out_features)),\n",
    "            activation\n",
    "        )\n",
    "\n",
    "class SNMLP(MLP):\n",
    "    def __init__(\n",
    "        self, in_features: int, out_features: int, layer_width: list,\n",
    "        combo=SNLinearCombo):\n",
    "        super().__init__(in_features, out_features, layer_width, combo)\n",
    "\n",
    "    def _build_model(self, combo):\n",
    "        model = nn.Sequential()\n",
    "        idx = -1\n",
    "        for idx, (in_ftr, out_ftr) in enumerate(self.layer_sizes[:-1]):\n",
    "            model.add_module(str(idx), combo(in_ftr, out_ftr))\n",
    "        # Note here is the main difference: the last layer also has spectral normalization\n",
    "        # This was not the case in the previous MLP definition\n",
    "        model.add_module(str(idx+1), spectral_norm(nn.Linear(*self.layer_sizes[-1])))\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: false\n",
    "width = ambient_dim * 16\n",
    "# Note in particular the lack of the bottleneck choice below\n",
    "# That is, we don't need to actually pick a bottleneck dimension -- LVA automatically determines this, like PCA\n",
    "encoder = MLP(ambient_dim, ambient_dim, [width] * 4)\n",
    "# Note also the change in the decoder to have spectral normalization\n",
    "decoder = SNMLP(ambient_dim, ambient_dim, [width] * 4)\n",
    "\n",
    "opt = torch.optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: false\n",
    "η, λ = 0.01, 0.01\n",
    "\n",
    "for i in range(20000):\n",
    "    opt.zero_grad()\n",
    "    z = encoder(X_torch)\n",
    "    rec_loss = F.mse_loss(decoder(z), X_torch)\n",
    "    # Note below the least volume loss\n",
    "    vol_loss = torch.exp(torch.log(z.std(0) + η).mean())\n",
    "    loss = rec_loss + λ * vol_loss\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "\n",
    "\n",
    "    if (i+1) % 1000 == 0:\n",
    "        # Print floats with 5 significant digits and fill epoch with leading spaces if under 4 digits\n",
    "        print(f'Epoch {i:4}: rec = {rec_loss:.5g}, vol = {vol_loss:.5g}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "X_P = decoder(encoder(X_torch)).detach().numpy()\n",
    "#X_P = decoded.detach().numpy()\n",
    "\n",
    "ax.scatter(X[:,0], X[:,1], X[:,2],alpha=0.5)\n",
    "ax.scatter(X_P[:,0], X_P[:,1], X_P[:,2])\n",
    "ax.set_xlabel('$X_0$')\n",
    "ax.set_ylabel('$X_1$')\n",
    "ax.set_zlabel('$X_2$')\n",
    "ax.elev=25\n",
    "ax.azim=10\n",
    "plt.legend(['Original Data','Reconstructed Data'])\n",
    "plt.title(\"AE Reconstruction\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.eval()\n",
    "decoder.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    z = encoder(X_torch)\n",
    "idx = z.std(0).argsort(descending=True)\n",
    "\n",
    "plt.scatter(z[:, idx[0]].cpu().detach().numpy(), z[:, idx[1]].cpu().detach().numpy(), s=10)\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.xlabel('$z_0$')\n",
    "plt.ylabel('$z_1$')\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(z[:, idx[0]].cpu().detach().numpy(), z[:, idx[2]].cpu().detach().numpy(),s=10)\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.xlabel('$z_0$')\n",
    "plt.ylabel('$z_2$')\n",
    "plt.show()\n",
    "\n",
    "# Plot the latent STDs by magnitude in the sorted order:\n",
    "plt.figure()\n",
    "plt.bar(np.arange(z.std(0).size(-1)), z.std(0)[idx])\n",
    "plt.title('latent STDs (autoencoder)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74",
   "metadata": {},
   "source": [
    "Plotting the latent code covariances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = z.T[idx].cov().detach().cpu().numpy()\n",
    "plt.matshow(cov, cmap='cool')\n",
    "for (i, j), var in np.ndenumerate(cov):\n",
    "    plt.gca().text(j, i, '{:.2e}'.format(var), ha='center', va='center')\n",
    "plt.title('Latent Covariance Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(z.cpu().detach().numpy(), columns=[f'z{i}' for i in range(z.shape[1])])\n",
    "plt.figure()\n",
    "sns.pairplot(df)\n",
    "plt.suptitle('Latent Space Pairplot', y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77",
   "metadata": {},
   "source": [
    "Let's check again the reconstruction errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = decoder(z).detach()\n",
    "\n",
    "for i in range(X_torch.size(-1)):\n",
    "    plt.figure(figsize=(3,3))\n",
    "    plt.scatter(X[:, i], X_[:, i], s=3)\n",
    "    plt.gca().set_aspect('equal')\n",
    "    plt.xlabel('groundtruth')\n",
    "    plt.ylabel('reconstruction')\n",
    "    plt.title('$x_{}$'.format(i))\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml4me-student",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
