{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "THhdvLWjsK6u"
   },
   "source": [
    "## PS1 Part 3: Bi-Linear Models and SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "In4rFDt8sK6w"
   },
   "source": [
    "### Bilinear Models for Recommendation\n",
    "\n",
    "For this problem, you will derive a very simple recommendation system that uses a combination of unsupervised and supervised approachs and demonstrates use of Stochastic Gradient Descent.\n",
    "\n",
    "Specifically, in class we discussed recommender models of the form:\n",
    "$$\n",
    "f(user,movie) = \\langle v_u,v_m \\rangle + b_u + b_m + \\mu\n",
    "$$\n",
    "\n",
    "where $v$ is a vector that represents a user's or movie's location in an N-Dimensional space, $b$ is a vector that represents a specific \"bias\" term for each movie and user, and $\\mu$ is a scalar that represents a kind of global anchor or base score (i.e., a sort of average movie rating). This means that each user has two vectors (e.g., $v_{\\mathrm{jack~smith}}$ and $b_{\\mathrm{jack~smith}}$), and each movie has two vectors (e.g., $v_{\\mathrm{Avengers}}$ and $b_{\\mathrm{Avengers}}$), with each of those vectors being N-Dimensional (in class we used two dimensions). For this, we constructed a loss function as follows:\n",
    "$$\n",
    "Cost = Loss + Penalty\n",
    "$$\n",
    "where\n",
    "$$\n",
    "Loss = \\Sigma_{(u,m)\\in \\mathrm{Ratings}} \\frac{1}{2}\\left( \\langle v_u,v_m \\rangle + b_u + b_m + \\mu - y_{u,m}\\right)^2\n",
    "$$\n",
    "and\n",
    "$$\n",
    "Penalty = \\frac{\\lambda}{2}\\left(\\Sigma_u \\left[\\| v_u\\|^2_2 + b_u^2\\right] + \\Sigma_m \\left[\\|v_m\\|^2_2 + b_m^2\\right]\\right)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yQaY3TV1sK6x"
   },
   "source": [
    "### Task 1: Analytical Gradients\n",
    "To use stochastic gradient descent, we first need to write down the gradients. Using the above cost function (including both the loss and penalty), compute the following partial derivatives:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\textrm{Cost}}{\\partial v_u } = \\frac{\\partial \\textrm{Loss}}{\\partial v_u} + \\frac{\\partial \\textrm{Penalty}}{\\partial v_u}\n",
    "= \\Sigma_{(u,m)\\in \\mathrm{Ratings}} \\left(\\langle v_u,v_m \\rangle + b_u + b_m + \\mu - y_{u,m}\\right)\\frac{\\partial \\left(\\langle v_u,v_m \\rangle + b_u + b_m + \\mu - y_{u,m}\\right)}{\\partial v_u} \n",
    "+ \\frac{\\lambda}{2} \\frac{\\partial \\left(\\Sigma_u \\left[\\| v_u\\|^2_2 + b_u^2\\right] + \\Sigma_m \\left[\\|v_m\\|^2_2 + b_m^2\\right]\\right)}{\\partial v_u} \n",
    "$$\n",
    "$$\n",
    "=\\Sigma_{(u,m)\\in \\mathrm{Ratings}} \\left(\\langle v_u,v_m \\rangle + b_u + b_m + \\mu - y_{u,m}\\right)\\frac{\\partial \\langle v_u,v_m \\rangle}{\\partial v_u} + \\frac{\\lambda}{2}\\Sigma_u \\frac{\\partial \\| v_u\\|^2_2}{\\partial v_u} = \\Sigma_{(u,m)\\in \\mathrm{Ratings}} \\left(\\langle v_u,v_m \\rangle + b_u + b_m + \\mu - y_{u,m}\\right)v_m + \\lambda\\Sigma_u v_u\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\textrm{Cost}}{\\partial v_m } = \\Sigma_{(u,m)\\in \\mathrm{Ratings}} \\left(\\langle v_u,v_m \\rangle + b_u + b_m + \\mu - y_{u,m}\\right)\\frac{\\partial \\langle v_u,v_m \\rangle}{\\partial v_m} + \\frac{\\lambda}{2}\\Sigma_m \\frac{\\partial \\| v_m\\|^2_2}{\\partial v_m} = \\Sigma_{(u,m)\\in \\mathrm{Ratings}}\\left(\\langle v_u,v_m \\rangle + b_u + b_m + \\mu - y_{u,m}\\right)v_u + \\lambda\\Sigma_m v_m\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\textrm{Cost}}{\\partial b_u} = \\Sigma_{(u,m)\\in \\mathrm{Ratings}} \\left(\\langle v_u,v_m \\rangle + b_u + b_m + \\mu - y_{u,m}\\right)\\frac{\\partial \\left(\\langle v_u,v_m \\rangle + b_u + b_m + \\mu - y_{u,m}\\right)}{\\partial b_u} \n",
    "+ \\frac{\\lambda}{2} \\frac{\\partial \\left(\\Sigma_u \\left[\\| v_u\\|^2_2 + b_u^2\\right] + \\Sigma_m \\left[\\|v_m\\|^2_2 + b_m^2\\right]\\right)}{\\partial b_u}\n",
    "$$\n",
    "$$\n",
    "= \\Sigma_{(u,m)\\in \\mathrm{Ratings}} \\left(\\langle v_u,v_m \\rangle + b_u + b_m + \\mu - y_{u,m}\\right)\\frac{\\partial b_u}{\\partial b_u} + \\frac{\\lambda}{2}\\Sigma_u \\frac{\\partial b_u^2}{\\partial b_u}\n",
    "= \\Sigma_{(u,m)\\in \\mathrm{Ratings}}\\left(\\langle v_u,v_m \\rangle + b_u + b_m + \\mu - y_{u,m}\\right) + \\lambda\\Sigma_u b_u\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\textrm{Cost}}{\\partial b_m} = \\Sigma_{(u,m)\\in \\mathrm{Ratings}} \\left(\\langle v_u,v_m \\rangle + b_u + b_m + \\mu - y_{u,m}\\right)\\frac{\\partial b_m}{\\partial b_m} + \\frac{\\lambda}{2}\\Sigma_m \\frac{\\partial b_m^2}{\\partial b_m} = \\Sigma_{(u,m)\\in \\mathrm{Ratings}} \\left(\\langle v_u,v_m \\rangle + b_u + b_m + \\mu - y_{u,m}\\right)+ \\lambda\\Sigma_m b_m\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\textrm{Cost}}{\\partial \\mu} = \\Sigma_{(u,m)\\in \\mathrm{Ratings}}\\left(\\langle v_u,v_m \\rangle + b_u + b_m + \\mu - y_{u,m}\\right)\n",
    "$$\n",
    "\n",
    "You can either do this directly in the notebook using LaTeX notation, or via a scanned image. Please remember to show your work in how you computed the derivatives, not just the final result. Note: Recall that the partial derivative of e.g. Nicholas's rating on Titanic with respect to the user Mark would be zero. When computing your SGD updates, consider how this might impact individual terms for users and movies in the loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-bc4GUAHsK6x"
   },
   "source": [
    "### Task 2: Stochastic Gradient Descent\n",
    "Now you are actually going to implement SGD on this type of model and optimize it until convergence on a toy dataset. To simplify the implementation, we'll actually make the model a little simpler than the one you derived updates for in task 1. Specifically, we'll just use:\n",
    "\n",
    "$$\n",
    "Cost = \\Sigma_{(u,m)\\in \\mathrm{Ratings}} \\frac{1}{2}\\left( \\langle v_u,v_m \\rangle + \\mu - y_{u,m}\\right)^2 + \\frac{\\lambda}{2}\\left(\\| v_u\\|^2_2 + \\|v_m\\|^2_2\\right)\n",
    "$$\n",
    "\n",
    "This way all you have to estimate is two vectors — $v_u$ for each user and $v_m$ for each movie — and $\\mu$ — a scalar value similar to an average rating. For simplicity, we'll assume here that the size of the latent space (K) is 2 (i.e., the length of each  $v_u$ & $v_m$).\n",
    "\n",
    "Using your above gradients, write down the update equations for each vector using stochastic gradient descent. Once you have done this, implement those update equations in code like we did in the in-class notebook. For simplicity, you can just use a constant step size $\\alpha$ if you wish, though you may change this if you want. Note: depending on exactly how you implement your model and what batch size you use, i.e., one point at a time, or some subset of data points, values of $\\alpha$ anywhere between around 0.7 and 0.01 should be sufficient to converge the model in under 1000 epochs, i.e., passes through the dataset. If you implement more advanced tricks covered in some optional readings this can converge much faster, but that is not necessary for this assignment, and it does not matter to me how quickly your model coverges, so long as it does so.\n",
    "\n",
    "Use the below small sample dataset of movie ratings for five users and six movies to perform stochastic gradient descent to update those vectors until your model converges. To initialize your SGD, you can use the initial weights/terms we provide below, or you can initialize the model any other way you wish -- the exact initialization should not make a big difference here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-RXFl6nNsK6x"
   },
   "outputs": [],
   "source": [
    "# Your Code below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pbRnHgU3sK6y",
    "outputId": "05af604a-9460-41f6-bb8b-b820cd821405"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "missing_ratings = pd.read_csv('missing.csv')\n",
    "ratings = pd.read_csv('ratings.csv')\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WA17sn3_sK6y",
    "outputId": "b10a6d2c-5a8e-4ba8-d929-8f00a66ebc48"
   },
   "outputs": [],
   "source": [
    "# Alternatively, if you prefer, you can convert it into numpy first:\n",
    "ratings_numpy = ratings.to_numpy()\n",
    "# ratings_numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tu3QvBMXsK6z"
   },
   "source": [
    "Let's initialize the vectors to some random numbers, and $\\mu$ to 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9OfcM3DYsK6z",
    "outputId": "28a202a9-68bb-4cc4-bb46-5849626b0e77"
   },
   "outputs": [],
   "source": [
    "K=2\n",
    "user_names = ratings['user'].unique()\n",
    "movie_names = ratings['movie'].unique()\n",
    "mu= 2.5\n",
    "# Setting the seed of the random generator to a value so that everyone sees the same initialization\n",
    "# should should be able to comment out the below with no ill-effects on whatever model you implement\n",
    "# this may just help us in office hours if folks have difficulty implementing things\n",
    "np.random.seed(0)\n",
    "V = pd.DataFrame(np.random.random((len(user_names)+len(movie_names),K)),index=np.hstack([user_names,movie_names]))\n",
    "print(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NEz_BXGPsK6z",
    "outputId": "48bde2a6-8577-4fe1-ae1c-80d6d2598569"
   },
   "outputs": [],
   "source": [
    "# Here is one example of how to go through rows of a ratings matrix\n",
    "for index, rating in ratings.iterrows():\n",
    "    user  = rating['user']\n",
    "    movie = rating['movie']\n",
    "    score = rating['ratings']\n",
    "    # print(f\"{user} gave {movie} a score of {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kfhmNy3YsK6z",
    "outputId": "a7c28801-d948-4b69-990b-49d2f87d8ec0"
   },
   "outputs": [],
   "source": [
    "# Here is an example of one way to access rows of V\n",
    "for index, rating in ratings.iterrows():\n",
    "    user  = rating['user']\n",
    "    movie = rating['movie']\n",
    "    # print(f\"{user}'s location in V is {V.loc[user].to_numpy()}.\")\n",
    "    # print(f\"{movie}'s location in V is {V.loc[movie].to_numpy()}.\")\n",
    "\n",
    "# You could also do it in Numpy directly, which will likely lead to much faster SGD updates,\n",
    "# but that shouldn't be necessary for problems of this size. Up to you!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zljHUktusK60"
   },
   "source": [
    "### Train your Bilinear Model using SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qUGe103fsK60"
   },
   "outputs": [],
   "source": [
    "# Your Model building and training code here!\n",
    "def cost(V,ratings,mu=2.5,lamb=0.1):\n",
    "    cost=0\n",
    "    for index, rating in ratings.iterrows():\n",
    "        user  = rating['user']\n",
    "        movie = rating['movie']\n",
    "        score = rating['ratings']\n",
    "        pred = V.loc[user].to_numpy().dot(V.loc[movie].to_numpy())\n",
    "        cost += 0.5*(score + mu - pred)**2\n",
    "    cost += lamb*0.5*(np.sum(V.loc[ratings['user'].unique()].to_numpy()**2) + np.sum(V.loc[ratings['movie'].unique()].to_numpy()**2))\n",
    "    #sum or no?..........|^|\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\Sigma_{(u,m)\\in \\mathrm{Ratings}} \\left(\\langle v_u,v_m \\rangle + \\mu - y_{u,m}\\right)v_m + \\lambda\\Sigma_u v_u\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def movieSum(V,ratings):\n",
    "    sum = 0\n",
    "    for idx,rating in ratings.iterrows():\n",
    "        user = rating['user']\n",
    "        movie = rating['movie']\n",
    "        score = rating['ratings']\n",
    "        v_user = V.loc[user].to_numpy()\n",
    "        v_movie = V.loc[movie].to_numpy()\n",
    "        bracket = v_user.dot(v_movie)+mu-score\n",
    "        sum += bracket * v_movie\n",
    "    return sum\n",
    "\n",
    "def userSum(V,ratings):\n",
    "    sum = 0\n",
    "    for idx,rating in ratings.iterrows():\n",
    "        user = rating['user']\n",
    "        movie = rating['movie']\n",
    "        score = rating['ratings']\n",
    "        v_user = V.loc[user].to_numpy()\n",
    "        v_movie = V.loc[movie].to_numpy()\n",
    "        bracket = v_user.dot(v_movie)+mu-score\n",
    "        sum += bracket * v_user\n",
    "    return sum\n",
    "\n",
    "def grad_step_old(V,ratings,alpha,lamb):\n",
    "    V -= alpha*np.array([movieSum(V,ratings) + lamb*v if int(i) < 5 else userSum(V,ratings)+lamb*v for i, (idx, v) in enumerate(V.iterrows())])\n",
    "\n",
    "def grad_step(V,rating,alpha,lamb):\n",
    "    global mu\n",
    "    error = V.loc[rating['user']].to_numpy().dot(V.loc[rating['movie']].to_numpy()) + mu - rating['ratings']\n",
    "    v_m = V.loc[rating['movie']].to_numpy()\n",
    "    v_u = V.loc[rating['user']].to_numpy()\n",
    "    V.loc[rating['user']] -= alpha * (error * v_m + lamb * v_u)\n",
    "    V.loc[rating['movie']] -= alpha * (error * v_u + lamb * v_m)\n",
    "    temp_mu = mu - alpha * error\n",
    "    return temp_mu\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualise vectors with arrows\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_vectors(V,ratings):\n",
    "\n",
    "    plt.figure()\n",
    "    for i,(idx,_)in enumerate(V.iterrows()):\n",
    "        if i < 5:\n",
    "            plt.arrow(0,0,V.iloc[i,0],V.iloc[i,1],color='blue',alpha=0.3)\n",
    "        else:\n",
    "            plt.arrow(0,0,V.iloc[i,0],V.iloc[i,1],color='red',alpha=0.3)\n",
    "\n",
    "    plt.scatter(V.loc[ratings['user'].unique()][0],V.loc[ratings['user'].unique()][1],label='Users',color='blue')\n",
    "    plt.scatter(V.loc[ratings['movie'].unique()][0],V.loc[ratings['movie'].unique()][1],label='Movies',color='red')\n",
    "\n",
    "    for i,(idx,_)in enumerate(V.iterrows()):\n",
    "        if i < 5:\n",
    "            plt.text(V.iloc[i,0] +.02, V.iloc[i,1] + .01, idx, fontsize=8)\n",
    "        else:\n",
    "            plt.text(V.iloc[i,0] +.02, V.iloc[i,1] + .01, idx, fontsize=8)\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.xlabel('Dimension 1')\n",
    "    plt.ylabel('Dimension 2')\n",
    "    plt.title('User and Movie Vectors')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "# plot gradient\n",
    "# this needs to be fixed, update for single gradient calculation\n",
    "def plot_grad(V,ratings,alpha,lamb):\n",
    "    grads = alpha*np.array([movieSum(V,ratings) + lamb*v if int(i) < 5 else userSum(V,ratings)+lamb*v for i, (idx, v) in enumerate(V.iterrows())])\n",
    "    plt.figure()\n",
    "    for i,p in enumerate(grads):\n",
    "        if i < 5:\n",
    "            plt.arrow(V.iloc[i,0],V.iloc[i,1],p[0],p[1],color='skyblue')\n",
    "        else:\n",
    "            plt.arrow(V.iloc[i,0],V.iloc[i,1],p[0],p[1],color='orange')\n",
    "    plt.scatter(V.loc[ratings['user'].unique()][0],V.loc[ratings['user'].unique()][1],label='Users',color='blue',s=5)\n",
    "    plt.scatter(V.loc[ratings['movie'].unique()][0],V.loc[ratings['movie'].unique()][1],label='Movies',color='red',s=5)\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "alpha = 0.1     # Step size\n",
    "lamb = 0.1     # Penalizes large vectors\n",
    "shuffle_after_pass = True\n",
    "index = list(range(ratings.shape[0]))\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    if shuffle_after_pass:\n",
    "        np.random.shuffle(index)\n",
    "    for i in index:\n",
    "        mu = grad_step(V,ratings.iloc[i],alpha,lamb)\n",
    "    if epoch % 100 == 0:\n",
    "        plot_vectors(V,ratings)\n",
    "        # maybe try plotting gradients as well\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9dQvSvvxsK60"
   },
   "source": [
    "### Assessing your accuracy\n",
    "Let's predict the ratings for the missing entries using our (randomly initialized) model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4WDCUDkzsK60",
    "outputId": "224356e6-476b-4453-8d84-d00bb42ecaa1"
   },
   "outputs": [],
   "source": [
    "for index, rating in missing_ratings.iterrows():\n",
    "    user  = rating['user']\n",
    "    movie = rating['movie']\n",
    "    prediction = np.dot(V.loc[user],V.loc[movie])+mu\n",
    "    print(f\"Prediction: {user} will rate {movie}: {prediction:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ml4me-student",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
