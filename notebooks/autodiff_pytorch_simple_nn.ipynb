{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of PyTorch SGD for Linear Regression and a Simple Feed-Forward Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_context('poster')\n",
    "np.random.seed(1)\n",
    "\n",
    "n_samples = 30\n",
    "\n",
    "# True Function we want to estimate\n",
    "true_fun = lambda X: np.cos(1.5 * np.pi * X)\n",
    "\n",
    "# Noisy Samples from the true function\n",
    "X = np.sort(2*np.random.rand(n_samples)-1)\n",
    "y = true_fun(X) + np.random.randn(n_samples) * 0.1\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "# Plot the true function:\n",
    "X_plot = np.linspace(-1.5, 1.5, 100)\n",
    "plt.plot(X_plot, true_fun(X_plot), '--',label=\"True function\")\n",
    "# Plot the data samples\n",
    "plt.scatter(X,y, label=\"Samples\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.4, random_state=0)\n",
    "plt.figure(figsize=(7,7))\n",
    "# Plot the data samples\n",
    "plt.scatter(X_train,y_train, label=\"Train\", c='Blue', s=20, edgecolors='none')\n",
    "plt.scatter(X_test,y_test, label=\"Test\", c='Red', s=50, edgecolors='none')\n",
    "#plt.plot(X_plot, true_fun(X_plot), 'g--',label=\"True function\")\n",
    "plt.legend(loc=\"best\")\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data into a shape and data-type that PyTorch likes\n",
    "X_train = X_train.reshape(-1,1).astype(np.float32)\n",
    "y_train = y_train.reshape(-1,1).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size  = 1\n",
    "output_size = 1\n",
    "# Linear regression model\n",
    "model = nn.Linear(input_size, output_size)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "learning_rate = 0.1 # alpha\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "num_epochs = 500\n",
    "for epoch in range(num_epochs):\n",
    "    # Convert numpy arrays to torch tensors\n",
    "    inputs = torch.from_numpy(X_train)\n",
    "    targets = torch.from_numpy(y_train)\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, targets)\n",
    "    \n",
    "    # Backward and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch+1) % 20 == 0:\n",
    "        print ('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the graph\n",
    "plt.plot(X_train, y_train, 'ro', label='Data')\n",
    "#predicted = model(torch.from_numpy(X_train)).detach().numpy()\n",
    "#plt.plot(X_train, predicted, 'b+',label='Predictions')\n",
    "predicted = model(torch.from_numpy(X_plot.reshape(-1,1).astype(np.float32))).detach().numpy()\n",
    "plt.plot(X_plot, predicted, 'b', label='Prediction')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of Defining a Network via the full Module class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(Net, self).__init__()  \n",
    "        # Fully-Connected Layer: 1 (input data) -> 5 (hidden node)\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)  \n",
    "        \n",
    "        # Non-Linear Layer\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        # You can try other kinds as well\n",
    "        # self.relu = nn.ReLU()\n",
    "        # self.elu = nn.ELU()\n",
    "        \n",
    "        \n",
    "        # Fully-Connected Layer: 5 (hidden node) -> 1 (output)\n",
    "        self.fc2 = nn.Linear(hidden_size, 1) \n",
    "    \n",
    "    # Forward pass builds the model prediction from the inputs\n",
    "    def forward(self, x):                              \n",
    "        out = self.fc1(x)\n",
    "        out = self.sigmoid(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "    \n",
    "# Build the network -- is it not trained yet\n",
    "model = Net(input_size=1, hidden_size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of building a model using the `Sequential` helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size=1\n",
    "hidden_size=4\n",
    "model = nn.Sequential(\n",
    "          nn.Linear(input_size, hidden_size),\n",
    "          nn.Sigmoid(),\n",
    "          nn.Linear(hidden_size, hidden_size),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(hidden_size, 1)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example using Python list expansions to help build deeper networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size=1\n",
    "hidden_size=7\n",
    "num_hidden_layers = 3\n",
    "activation = nn.ReLU\n",
    "\n",
    "input_layer = [nn.Linear(input_size, hidden_size),\n",
    "                activation()]\n",
    "hidden_layers = num_hidden_layers*[nn.Linear(hidden_size, hidden_size), \n",
    "                                   activation()]\n",
    "output_layer = [ nn.Linear(hidden_size, 1) ] \n",
    "\n",
    "# Stack them all together\n",
    "layers = input_layer + hidden_layers + output_layer\n",
    "\n",
    "print(layers)\n",
    "\n",
    "# Use the * operator to \"expand\" or \"unpack\" the list\n",
    "model = nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's do the actual training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What Loss function should we use? MSE!\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# What Optimization procedure should we use?\n",
    "learning_rate = 0.05\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train the model\n",
    "\n",
    "# Convert numpy arrays to torch tensors\n",
    "inputs = torch.from_numpy(X_train)\n",
    "targets = torch.from_numpy(y_train)\n",
    "\n",
    "num_epochs = 5000\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    ## Do Forward pass\n",
    "    # Make predictions\n",
    "    outputs = model(inputs)\n",
    "    # Compute the loss function\n",
    "    loss = criterion(outputs, targets)\n",
    "    \n",
    "    ## Update the model\n",
    "    # Reset the optimizer gradients\n",
    "    optimizer.zero_grad()\n",
    "    # Compute the gradient of the loss function\n",
    "    loss.backward()\n",
    "    # Do an optimization step\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Print the loss\n",
    "    if (epoch+1) % 200 == 0:\n",
    "        print ('Epoch [{:4}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's plot the prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the graph\n",
    "predicted = model(torch.from_numpy(X_train)).detach().numpy()\n",
    "plt.plot(X_train, y_train, 'ro', label='Data')\n",
    "#plt.plot(X_train, predicted, 'b+', label='Predictions')\n",
    "\n",
    "predicted = model(torch.from_numpy(X_plot.reshape(-1,1).astype(np.float32))).detach().numpy()\n",
    "plt.plot(X_plot, predicted, 'b', label='Prediction')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml4me-student",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
