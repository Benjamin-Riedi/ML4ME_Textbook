{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction to Linear Regression and Gradient Descent\n",
    "------\n",
    "\n",
    "In this notebook, we will review Linear Regression from the standpoint of Gradient Descent (instead of the normal equations), so as to build our intuition about how Gradient Descent works, and also introduce the concept of Stochastic Gradient Descent (SGD).\n",
    "\n",
    "Let's first set up our notation for the problem:\n",
    "$$\n",
    "y = w\\cdot x + b + \\epsilon\n",
    "$$\n",
    "Or, if we consider $x = [1, x]$ then:\n",
    "$$\n",
    "y = \\mathbf{w^T\\cdot x} + \\epsilon\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import make_regression\n",
    "sns.set_context('poster')\n",
    "\n",
    "\n",
    "n_samples = 100   # How many datapoints do we want?\n",
    "\n",
    "X, y, coef = make_regression(n_samples=n_samples, # How many data?\n",
    "                               n_features=1,    # How many dimensions?\n",
    "                               n_informative=1, # How many dimensions matter?\n",
    "                               noise=10,   # Add noise to the line\n",
    "                               coef=True,  # Return the coefficients for us\n",
    "                               random_state=0)  # Same random numbers every time\n",
    "\n",
    "print(\"Coefficient: {:.5s}\".format(str(coef)))\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.scatter(X,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From your earlier statistics classes, you likely learned how to solve for the linear regression weights using the [Normal Equations](https://en.wikipedia.org/wiki/Linear_least_squares_%28mathematics%29#Derivation_of_the_normal_equations):\n",
    "$$\n",
    "\\hat{w} = (X^T X)^{-1}X^T y\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.matrix(X)\n",
    "y = np.matrix(y).T\n",
    "wn = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)\n",
    "wn = wn[0,0]\n",
    "print(wn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.scatter(np.asarray(X).ravel(),np.asarray(y).ravel())\n",
    "plt.plot([-3,3],[-3*wn, 3*wn])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are ways of solving the normal equations directly without needing to take the inverse (such as using the [Cholesky decomposition](https://en.wikipedia.org/wiki/Cholesky_decomposition)), however today we are going to focus on a different kind of solver that has more broader applications: [Gradient Descent](https://en.wikipedia.org/wiki/Gradient_descent) and it's cousin [Stochastic Gradient Descent (SGD)](https://en.wikipedia.org/wiki/Stochastic_gradient_descent).\n",
    "\n",
    "We first need to start with some sort of Cost function that we wish to minimize. In general, we will consider costs of the form:\n",
    "$$\n",
    "Loss = Error + \\alpha\\cdot Penalty\n",
    "$$\n",
    "\n",
    "Specifically for Linear Models, we will talk about costs (which I'll call $J$) of the form:\n",
    "\n",
    "$$\n",
    "J(w,X) = \\frac{1}{N}\\Sigma_{i=1}^N \\left(\\mathbf{y}_i - f(\\mathbf{w},\\mathbf{x}_i)\\right)^2 + \\alpha\\cdot\\Omega(\\mathbf{w})\n",
    "$$\n",
    "\n",
    "where for Linear Models $f(w,X) = \\mathbf{w\\cdot X}$, so that our overall cost becomes:\n",
    "\n",
    "$$\n",
    "J(w,X) = \\frac{1}{N}\\Sigma_{i=1}^N \\left(\\mathbf{y}_i - \\mathbf{w\\cdot \\mathbf{x}_i}\\right)^2 + \\alpha\\cdot\\Omega(\\mathbf{w})\n",
    "$$\n",
    "\n",
    "We'll consider the no-penalty case ($\\alpha=0$), so that our loss is just:\n",
    "\n",
    "$$\n",
    "J(w,X) = \\frac{1}{N}\\Sigma_{i=1}^N \\left(\\mathbf{y}_i - \\mathbf{w\\cdot \\mathbf{x}_i}\\right)^2\n",
    "$$\n",
    "\n",
    "Let's plot this cost as a function of the line slope, just to get an idea of what it looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(w):\n",
    "    N = len(y)\n",
    "    return np.sum(np.square(y-w*X))/N\n",
    "\n",
    "wp = np.linspace(0,80,1000)\n",
    "cost = [loss(w) for w in wp]\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(wp,cost)\n",
    "plt.ylabel('Cost')\n",
    "plt.xlabel('slope (w)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While it might seem clear to us, visually, where the lowest cost is, actually finding this point automatically via a computer with minimal effort is another story. This is essentially what the field of Optimization tries to do. One simple (but powerful) method of optimization is Gradient Descent. It works by taking a (possibly random) starting point (e.g., w=60), and then computing the gradient of the function at that point. Since gradients will point upwards, and we want to minimize the cost, we will instead walk in the *negative* gradient direction, which should move us closer to the bottom. Let's see this on an example, by computing the gradient of our cost function above with respect to the slope (w):\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial J}{\\partial w} &=& \\frac{\\partial}{\\partial w} \\left( \\frac{1}{N}\\Sigma_{i=1}^N \\left(\\mathbf{y}_i - \\mathbf{w}\\cdot \\mathbf{x}_i\\right)^2 \\right) \\\\\n",
    "&=&\\frac{1}{N}\\Sigma_{i=1}^N  \\frac{\\partial}{\\partial w} \\left(\\left(\\mathbf{y}_i - \\mathbf{w}\\cdot \\mathbf{x}_i\\right)^2 \\right) \\\\\n",
    "&=&\\frac{2}{N}\\Sigma_{i=1}^N (\\mathbf{y}_i - \\mathbf{w}\\cdot \\mathbf{x}_i) \\frac{\\partial}{\\partial w} \\left(\\mathbf{y}_i - \\mathbf{w}\\cdot \\mathbf{x}_i \\right) \\\\\n",
    "&=&-\\frac{2}{N}\\Sigma_{i=1}^N (\\mathbf{y}_i - \\mathbf{w}\\cdot \\mathbf{x}_i) \\cdot \\mathbf{x}_i \n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Let's plot this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dloss(w,X):\n",
    "    N = len(y)\n",
    "    return -2*np.sum(np.multiply(y-w*X,X))/N\n",
    "\n",
    "grad = [dloss(w,X) for w in wp]\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(wp,grad)\n",
    "plt.ylabel('Gradient')\n",
    "plt.xlabel('slope (w)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have 1) a starting point, and 2) the gradient at a point, the idea with gradient descent is to take a small step ($\\alpha$) in the direction of the negative gradient:\n",
    "\n",
    "$$\n",
    "w_{t+1} = w_t - \\alpha \\frac{\\partial J}{\\partial w}\n",
    "$$\n",
    "\n",
    "Note: here we are just considering a single parameter (the slope, w), but this method extends to multiple parameters ($\\mathbf{\\theta}$), via the gradient operator:\n",
    "\n",
    "$$\n",
    "\\mathbf{\\theta}_{t+1} = \\mathbf{\\theta}_t - \\alpha \\nabla_\\theta J\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_step(w, X, alpha):\n",
    "    return w - alpha*dloss(w,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wg = 42  # Start at 50\n",
    "wg = grad_step(wg, X, 0.1)  # Take a small step\n",
    "print(wg)  # Now we are at..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment: \n",
    "Try modifying the initial guess `wg` and the step size `alpha` and re-running the below cells. What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "# Try changing the below\n",
    "wg = 80 # Initial guess at slope; Try changing this\n",
    "alpha = 0.1  # Try changing alpha (both big and small)\n",
    "# What do you notice?\n",
    "###########################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_steps = 20 # Take 20 steps\n",
    "weights = np.zeros(num_steps)\n",
    "weights[0] = wg  # Set the initial weight\n",
    "for i in range(1,num_steps): \n",
    "    weights[i] = grad_step(weights[i-1], X, alpha)\n",
    "print(\"Final weight from Gradient Descent is {:.2f}\".format(weights[i]))\n",
    "print(\"Compared to {:.2f} from the Normal Equations\".format(wn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_cost = [loss(w) for w in weights]\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(wp,cost)\n",
    "plt.scatter(weights,weight_cost,facecolors='none', edgecolors='r',linewidth=1)\n",
    "ax = plt.gca()\n",
    "for i,w in enumerate(weights):\n",
    "    ax.annotate('{}'.format(i), xy=(w, weight_cost[i]-10), \n",
    "                xytext=(w+1e-8, 10+50*np.random.rand()),\n",
    "                ha='center',fontsize=8,\n",
    "                arrowprops=dict(facecolor='white', edgecolor='grey',\n",
    "                                shrink=0.05,\n",
    "                            width=1, headwidth=1)\n",
    "               )\n",
    "plt.ylabel('Cost')\n",
    "plt.xlabel('slope (w)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot how the weights progress\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(range(len(weights)),weights, label='GD')\n",
    "plt.hlines(wn, 0, len(weights), \n",
    "           label = \"Optimal Weight\", \n",
    "           color='k', linestyle=\"--\")\n",
    "plt.xlabel('Gradient Descent Iteration')\n",
    "plt.ylabel('Weight')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# Copying for comparison later\n",
    "gd_weights = weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Descent\n",
    "To perform Gradient Descent, we needed to sum the gradients across all data points (to compute $\\nabla J$). We may not want to do this, for many reasons: 1) we may not be able to iterate through all the data points easily (maybe the data are split across many computers or files), 2) we may not want to store the data at all after we are done with it (online learning), 3) maybe computing the gradient for one data point is difficult, and we would like to make forward progress on the model while computing gradients of other points, *etc.*\n",
    "\n",
    "This is where *Stochastic* Gradient Descent comes it. Rather than Gradient Descent, which computes the gradient over all the data ($\\mathbf{X}$):\n",
    "$$\n",
    "\\mathbf{w}_{t+1} = \\mathbf{w}_t - \\alpha \\frac{\\partial J(\\mathbf{w},\\mathbf{X})}{\\partial \\mathbf{w}}\n",
    "$$\n",
    "\n",
    "Stochastic Gradient Descent computes a similar quantity, but only over one data point ($\\mathbf{x}_i$) at a time (or a small batch of data if that is feasible):\n",
    "$$\n",
    "\\mathbf{w}_{t+1} = \\mathbf{w}_t - \\alpha \\frac{\\partial J(\\mathbf{w},\\mathbf{x}_i)}{\\partial \\mathbf{w}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd_dloss(w,y,x):\n",
    "    return float(-2*(y-w*x)*x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "# Try Changing the below\n",
    "wg = 80 # Initial guess at slope\n",
    "alpha = 0.05  # Step Size\n",
    "num_passes = 40  # Number of times we pass through the data\n",
    "shuffle_after_pass = False  # Whether to shuffle the data\n",
    "##########################\n",
    "# What do you find?\n",
    "\n",
    "N = len(y)\n",
    "weights = np.zeros(N*num_passes+1)\n",
    "k=0\n",
    "weights[k] = wg  # Set the initial weight\n",
    "print('Initial weight: ',weights[0])\n",
    "\n",
    "index = list(range(N))\n",
    "for n in range(num_passes):\n",
    "    if shuffle_after_pass:\n",
    "        np.random.shuffle(index)\n",
    "    for i in index:\n",
    "        k+=1\n",
    "        xi = X[i,0]\n",
    "        yi = y[i]\n",
    "        weights[k] = weights[k-1] - alpha*sgd_dloss(weights[k-1],yi,xi)\n",
    "print('Final Weight from SGD: {:.2f}'.format(weights[-1]))\n",
    "print(\"Compared to {:.2f} (Normal Equations)\".format(wn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(range(len(weights)),weights)\n",
    "plt.hlines(wn, 0, len(weights), \n",
    "           label = \"Optimal Weight\", \n",
    "           color='k', linestyle=\"--\")\n",
    "plt.xlabel('SGD Iteration/# Samples Used')\n",
    "plt.ylabel('Weight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(range(len(weights)), weights,\n",
    "         label = 'SGD')\n",
    "plt.plot(np.array(range(len(gd_weights)))*len(index),\n",
    "         gd_weights,\n",
    "         marker='o',\n",
    "         label = 'GD')\n",
    "plt.hlines(wn, 0, len(weights), \n",
    "           label = \"Optimal Weight\", \n",
    "           color='k', linestyle=\"--\")\n",
    "plt.xlabel('# Samples Used')\n",
    "plt.ylabel('Weight')\n",
    "#plt.ylim([30,55])\n",
    "plt.xlim([0,len(weights)])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment:\n",
    "What do you notice about the behavior of SGD? What happens when alpha is small vs large? What happens when you take multiple passes through the data? If I keep  doing more passes, do I eventually converge?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "What you are seeing is a result of [Stochastic Approximation](https://en.wikipedia.org/wiki/Stochastic_approximation) (trying to approximate a gradient of a function using noisy estimates of that gradient (where the noise here comes from evaluating the gradient using only one data point).\n",
    "\n",
    "This behavior was studied by multiple people in the 1950s and 60s, with one key result coming Herbert Robbins and Sutton Monro, in what is now called the [Robbins-Monro Algorithm](https://en.wikipedia.org/wiki/Stochastic_approximation#Robbins.E2.80.93Monro_algorithm). The central idea is rather than defining a *single* step size, we should let the step size decrease over time. Initially, we need to move the weights a lot, but as we get closer to the goal, they exert less influence so that we *settle* at some point. What they showed was that SGD would converge to the right estimator so long as the sequence satisfies the following properties:\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\sum_{n=1}^{\\infty} a_n &= \\infty \\\\\n",
    "\\sum_{n=1}^{\\infty} a_n^2 &< \\infty\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "For sequences where $a_n>0~\\forall~n>0$, Robbins and Monro recommended the $a_n = a/n$, however this rate is based on some assumptions about smoothness and convexity which sometimes don't work well in practice. People generally use decay rates on the order of $O(1/\\sqrt(n))$,  however there are entire fields of researchers working on this \"optimal step size\" problem for SGD and there are many great alternative procedures out there if you know certain things about the function (e.g., can compute things like hessians, etc.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "# Try Changing the below\n",
    "wg = 80 # Initial guess at slope\n",
    "alpha_i = 0.5  # Initial Step Size\n",
    "#alpha = lambda n: alpha_i\n",
    "#alpha = lambda n: alpha_i/n\n",
    "alpha = lambda n: alpha_i/np.sqrt(n)\n",
    "num_passes = 5  # Number of times we pass through the data\n",
    "shuffle_after_pass = True  # Whether to shuffle the data\n",
    "##########################\n",
    "# What do you find?\n",
    "\n",
    "N = len(y)\n",
    "weights = np.zeros(N*num_passes+1)\n",
    "k=0\n",
    "weights[k] = wg  # Set the initial weight\n",
    "print('Initial weight: ',weights[0])\n",
    "\n",
    "index = list(range(N))\n",
    "for n in range(num_passes):\n",
    "    if shuffle_after_pass:\n",
    "        np.random.shuffle(index)\n",
    "    for i in index:\n",
    "        k+=1\n",
    "        xi = X[i,0]\n",
    "        yi = y[i]\n",
    "        weights[k] = weights[k-1] - alpha(k)*sgd_dloss(weights[k-1],yi,xi)\n",
    "print('Final Weight from SGD: {:.2f}'.format(weights[-1]))\n",
    "print(\"Compared to {:.2f} (Normal Equations)\".format(wn))\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "# Plot SGD Weights\n",
    "plt.plot(range(len(weights)), weights,\n",
    "         marker=None,\n",
    "         label = 'SGD')\n",
    "# Plot Grad. Descent Weights\n",
    "plt.plot(np.array(range(len(gd_weights)))*len(index),\n",
    "         gd_weights,\n",
    "         marker='o',\n",
    "         label = 'GD')\n",
    "# Plot True Answer\n",
    "plt.hlines(wn, 0, len(weights), \n",
    "           label = \"Optimal Weight\", \n",
    "           color='k', linestyle=\"--\")\n",
    "plt.xlabel('# Samples Used')\n",
    "plt.ylabel('Weight')\n",
    "#plt.ylim([30,55])\n",
    "plt.xlim([0,len(weights)])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While Gradient Descent looks much better than SGD here, let's now scale the axis by the number of model evaluations needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(range(len(weights)), weights,\n",
    "         label = 'SGD')\n",
    "plt.plot(np.array(range(len(gd_weights)))*len(index),\n",
    "         gd_weights,\n",
    "         marker='o',\n",
    "         label = 'GD')\n",
    "plt.hlines(wn, 0, len(weights), \n",
    "           label = \"Optimal Weight\", \n",
    "           color='k', linestyle=\"--\")\n",
    "#plt.ylim([35,50])\n",
    "plt.xlim([0,len(weights)])\n",
    "plt.xlabel('# Samples Used')\n",
    "plt.ylabel('Weight')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(range(len(gd_weights)))*len(index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Existing Implementations\n",
    "SGD is a fairly simple and popular technique for solving many problems where you can easily express the derivatives of those functions. For certain types of loss function (like the square error/L2 norm we discussed above), many folks have written optimized libraries for just that purpose, such as Scikit-Learn's [SGD functions](http://scikit-learn.org/stable/modules/sgd.html) including [SGDRegressor](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html#sklearn.linear_model.SGDRegressor).\n",
    "\n",
    "For reference, the SGD Regressor in ScikitLearn uses an update rule similar to:\n",
    "$$\n",
    "\\eta^{(t)} = \\frac{eta_0}{t^{power_t}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "sgd = SGDRegressor(loss = 'squared_error',\n",
    "                   eta0 = 0.01,  # Initial Learning rate/step size\n",
    "                   power_t = 0.25, # how quickly sould eta decay?\n",
    "                   max_iter = 100,  # Max # of passes to do over the data?\n",
    "                   tol = 1e-3,     # Tolerance for change in loss\n",
    "                   fit_intercept=False # Not worrying about b term in w*x+b\n",
    "                  )\n",
    "# Here eta = eta0/(t^power_t) where t is the iteration\n",
    "X = np.asarray(X)\n",
    "y = np.array(y).reshape(len(y),) # Reshape y so that scikit doesn't complain\n",
    "sgd.fit(X,y)\n",
    "print('Final Weight from SKLearn SGD: {:.2f}'.format(sgd.coef_[0]))\n",
    "print(\"Compared to {:.2f} (Normal Equations)\".format(wn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.scatter(np.asarray(X).ravel(),\n",
    "            np.asarray(y).ravel(),\n",
    "            color='k'\n",
    "           )\n",
    "#plt.scatter(X,y)\n",
    "Xp = [[-3],[3]]\n",
    "plt.plot(Xp,sgd.predict(Xp),label='SGD')\n",
    "plt.plot([-3,3],[-3*wn, 3*wn],\n",
    "         label='Normal Eqns',\n",
    "         linestyle='--' )\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Techniques\n",
    "There are a variety of more advanced SGD techniques, most of which involve one or more of the following tricks:\n",
    "1. Using \"acceleration\" procedures that leverage \"momentum\" of some type. You can read more about this phenomenon at: [\"Why Momentum Really Works\"](https://distill.pub/2017/momentum/)\n",
    "2. \"Batching\" the SGD updates: that is, taking steps that are considering $N>n>1$ in size (e.g., averaging the gradients of, say, 5 data points before taking a step). This can help stablize gradients and improve convergence.\n",
    "3. \"Normalizing\" the gradient updates: that is, re-scaling the gradient updates at each step to achieve better convergence. This is commonly used in Neural Networks for things like [Batch Normalization (Wikipedia)](https://en.wikipedia.org/wiki/Batch_normalization) (or, for a more advanced introduction, you can read the NeurIPS paper [Understanding Batch Normalization](https://papers.nips.cc/paper/7996-understanding-batch-normalization.pdf))."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
