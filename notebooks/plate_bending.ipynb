{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Improve Me\n",
    "\n",
    "When I was a student, I wrote this beautiful piece of code. It does not work. Help me improve it.\n",
    "\n",
    "Tip: use the instructions from [the ML4ME appendix](https://ideal.umd.edu/ML4ME_Textbook/appendices/helpful_tooling.html).\n",
    "\n",
    "## Imports\n",
    "\n",
    "You can add your own extra imports if you need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Data Generation and Processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### Context\n",
    "Imagine a factory producing metal plates for some engineering application.\n",
    "\n",
    "Each plate is supposed to have uniform properties, but in reality, manufacturing imperfections (slightly thinner material, internal stresses, micro-defects) can cause some parts of a plate to bend more than others when pressure is applied.\n",
    "\n",
    "Quality control wants to measure deflection at every point `(x, y)` of the plate. This requires physical experiments and is slow and expensive. That's why we're building an ML model that is able to predict deflection `z` at any `(x, y)` point.\n",
    "\n",
    "We don't have exact measures so we will construct an artificial dataset where the deflection is actually not uniform on one side (the plate has a thinner corner)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our physical model\n",
    "\n",
    "def generate_plate_data(n_samples: int = 100, n_plates: int = 5, noise_level: float = 0.2):\n",
    "    \"\"\"Generates multiple plates with a defect.\n",
    "\n",
    "    Args:\n",
    "        n_samples: number of points per plate\n",
    "        n_plates: number of plates\n",
    "        noise_level: noise level in the deflection\n",
    "\n",
    "    Returns:\n",
    "        X: input points\n",
    "        y: deflection\n",
    "    \"\"\"\n",
    "    n_sample_per_side = int(n_samples**0.5)\n",
    "    x = torch.linspace(-2, 2, n_sample_per_side)\n",
    "    y = torch.linspace(-2, 2, n_sample_per_side)\n",
    "    xx, yy = torch.meshgrid(x, y, indexing=\"ij\")\n",
    "    X_base = torch.stack([xx.flatten(), yy.flatten()], dim=1)\n",
    "\n",
    "    # Base deflection\n",
    "    r2 = X_base[:,0]**2 + X_base[:,1]**2\n",
    "    Z_base = torch.tanh(r2 / 5.0) * 5.0\n",
    "\n",
    "    # Mask for the top-right corner defect\n",
    "    corner_mask = (X_base[:,0] > 1.0) & (X_base[:,1] > 0.5)\n",
    "    # Aggressive corner defect with y-dependent variation\n",
    "    Z_base[corner_mask] *= 1 + 2*((X_base[corner_mask,0]-1.0)**2 + (X_base[corner_mask,1]-0.5)**2)\n",
    "    \n",
    "\n",
    "    # Replicate experiments with noise for different plates\n",
    "    X_list, y_list = [], []  # noqa: N806\n",
    "    for _ in range(n_plates):\n",
    "        Z_noisy = Z_base + noise_level * torch.randn_like(Z_base)  # noqa: N806\n",
    "        X_list.append(X_base)\n",
    "        y_list.append(Z_noisy)\n",
    "\n",
    "    # assemble the data\n",
    "    X = torch.cat(X_list, dim=0)  # noqa: N806\n",
    "    y = torch.cat(y_list, dim=0)\n",
    "    idx = torch.argsort(X[:,0])\n",
    "    X = X[idx]  # noqa: N806\n",
    "    y = y[idx]\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate full dataset\n",
    "X_all, y_all = generate_plate_data(n_samples=100, n_plates=5, noise_level=0.4)\n",
    "total_samples = X_all.shape[0]\n",
    "\n",
    "fig = plt.figure(figsize=(9,7))\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "ax.scatter(X_all[:,0], X_all[:,1], y_all, c=\"blue\", alpha=0.3)\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "ax.set_zlabel(\"deflection z\")\n",
    "ax.set_title(\"Plate deflection\")\n",
    "plt.show()\n",
    "\n",
    "# Split into train/test\n",
    "train_ratio = 0.7\n",
    "train_size = int(total_samples * train_ratio)\n",
    "X_train, y_train = X_all[:train_size], y_all[:train_size]\n",
    "X_test, y_test   = X_all[train_size:], y_all[train_size:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "x_scaler = StandardScaler()\n",
    "y_scaler = StandardScaler()\n",
    "\n",
    "# Normalizing our data, don't forget to unnormalize the predictions later!\n",
    "X_train_scaled = torch.from_numpy(x_scaler.fit_transform(X_train.numpy())).float()\n",
    "X_test_scaled = torch.from_numpy(x_scaler.transform(X_test.numpy())).float()\n",
    "y_train_scaled = torch.from_numpy(y_scaler.fit_transform(y_train.numpy().reshape(-1, 1))).float().squeeze()\n",
    "y_test_scaled = torch.from_numpy(y_scaler.transform(y_test.numpy().reshape(-1, 1))).float().squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition\n",
    "class NetleF(nn.Module):\n",
    "    \"\"\"A very efficient neural network for the given task, probably the best for the job.\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        layers.append(nn.Linear(2, 20)) # input layer\n",
    "        for _ in range(8):\n",
    "            layers.append(nn.Sigmoid()) # activation function\n",
    "            layers.append(nn.Linear(20, 20)) # hidden layer\n",
    "        layers.append(nn.Sigmoid()) # activation function\n",
    "        layers.append(nn.Linear(20, 1)) # output layer\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NetleF()\n",
    "\n",
    "# Optimizer and loss\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(200):\n",
    "    y_pred_scaled = model(X_train_scaled).squeeze()\n",
    "    loss = loss_fn(y_pred_scaled, y_train_scaled)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        with torch.no_grad(): # no gradients coming from the test set\n",
    "            test_pred_scaled = model(X_test_scaled).squeeze()\n",
    "            test_loss = loss_fn(test_pred_scaled, y_test_scaled)\n",
    "        print(f\"Epoch {epoch:3d} | Train loss: {loss.item():.4f} | Test loss: {test_loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## Visualization of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions vs targets in 3d\n",
    "with torch.no_grad():\n",
    "    test_pred_scaled = model(X_test_scaled).squeeze()\n",
    "    test_pred = torch.from_numpy(y_scaler.inverse_transform(test_pred_scaled.numpy().reshape(-1, 1))).float().squeeze()\n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "    ax = fig.add_subplot(111, projection=\"3d\")\n",
    "    ax.scatter(X_test[:, 0], X_test[:, 1], test_pred, c=\"blue\", alpha=0.4, label=\"Predictions\")\n",
    "    ax.scatter(X_test[:, 0], X_test[:, 1], y_test, c=\"red\", marker=\"x\", alpha=0.6, label=\"Targets\")\n",
    "    ax.set_xlabel(\"x\")\n",
    "    ax.set_ylabel(\"y\")\n",
    "    ax.set_zlabel(\"z\")\n",
    "    ax.set_title(\"Predictions vs Targets\")\n",
    "    ax.legend()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
