{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_context('poster')\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to Polynomial (Secretly Linear) Regression and Regularization\n",
    "Let's return to our example data from earlier, except this time instead of using KNN Regression, we will briefly introduce Linear Regression (which we will study in more detail next week), how to extend linear models to be (apparently) non-linear by adding features, and the concept of *Regularization* which will help us control the complexity of the linear regression model. Ultimately, the purpose of briefly introducing linear regression now is because it provides us a nice test-case where we have multiple model hyper-parameters that we will need to *tune* (or find the best settings of), and thus will motivate some of our interest in optimization which we will build upon in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 30\n",
    "\n",
    "# True Function we want to estimate\n",
    "true_fun = lambda X: np.cos(1.5 * np.pi * X)\n",
    "\n",
    "# Noisy Samples from the true function\n",
    "X = np.sort(np.random.rand(n_samples))\n",
    "y = true_fun(X) + np.random.randn(n_samples) * 0.4\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "# Plot the true function:\n",
    "X_plot = np.linspace(0, 1, 100)\n",
    "plt.plot(X_plot, true_fun(X_plot), '--',label=\"True function\")\n",
    "# Plot the data samples\n",
    "plt.scatter(X,y, label=\"Samples\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just for the purposes of display, set the print precision to 2 decimals\n",
    "%precision 2\n",
    "t=X[:,np.newaxis]\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = np.sqrt(t)\n",
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t3 = np.exp(t)\n",
    "t3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.ones(len(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.hstack([t,t2,t3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
    "LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "X_stacked_example = np.hstack([t,t2,t3])\n",
    "lr.fit(X_stacked_example,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.predict(X_stacked_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's see how it does:\n",
    "X_plot = np.linspace(0, 1, 100)\n",
    "#plt.plot(X_plot, lr.predict(X_plot[:, np.newaxis]), label=\"Model\")\n",
    "plt.plot(X_stacked_example[:,0], lr.predict(X_stacked_example), label=\"Model\")\n",
    "plt.plot(X_plot, true_fun(X_plot), '--',label=\"True function\")\n",
    "plt.scatter(X, y, label=\"Samples\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.xlim((0, 1))\n",
    "plt.ylim((-2, 2))\n",
    "#plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's build some Polynomial features:\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "d=3\n",
    "pfeatures = PolynomialFeatures(degree=d,include_bias=True)\n",
    "X_new = pfeatures.fit_transform(X[:, np.newaxis])\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_new,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "# Here is a list of different degree polynomials to try out\n",
    "degrees = [1,2,3,5,10,15,20,30]\n",
    "\n",
    "# Generate samples of the true function + noise\n",
    "X = np.sort(np.random.rand(n_samples))\n",
    "noise_amount = 0.4\n",
    "y = true_fun(X) + np.random.randn(n_samples) * noise_amount\n",
    "\n",
    "# For each of the different polynomial degrees we listed above\n",
    "for d in degrees:\n",
    "    plt.figure(figsize=(7, 7)) # Make a new figure\n",
    "    # Construct the polynomial features\n",
    "    polynomial_features = PolynomialFeatures(degree=d,\n",
    "                                             include_bias=False)\n",
    "    # Construct linear regression model\n",
    "    linear_regression = LinearRegression()\n",
    "    pipeline = Pipeline([(\"polynomial_features\", polynomial_features),\n",
    "                         (\"linear_regression\", linear_regression)])\n",
    "    # Now fit the data first through the \n",
    "    # polynomial basis, then do regression\n",
    "    pipeline.fit(X[:, np.newaxis], y)\n",
    "    \n",
    "    # Get the accuracy score of the trained model\n",
    "    # on the original training data\n",
    "    score = pipeline.score(X[:, np.newaxis],y)\n",
    "\n",
    "    # Plot the results\n",
    "    X_plot = np.linspace(0, 1, 100)\n",
    "    plt.plot(X_plot, pipeline.predict(X_plot[:, np.newaxis]), label=\"Model\")\n",
    "    plt.plot(X_plot, true_fun(X_plot), '--',label=\"True function\")\n",
    "    plt.scatter(X, y, label=\"Samples\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.xlim((0, 1))\n",
    "    plt.ylim((-2, 2))\n",
    "    plt.legend(loc=\"best\")\n",
    "    \n",
    "    # Print the polynomial degree and the training\n",
    "    # accuracy in the title of the graph\n",
    "    plt.title(\"Degree {}\\nTrain score = {:.3f}\".format(\n",
    "        d, score))\n",
    "    plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regression.coef_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is going on here? To understand this, we need to understand something about how the model is optimizing error. \n",
    "\n",
    "Show Linear Regression MSE Example on board and introduce the idea of loss functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do we deal with this tradeoff? Regularization!\n",
    "$$\n",
    "Loss = Error(w,D) + \\alpha\\cdot\\Omega(w)\n",
    "$$\n",
    "where $\\Omega(w)$ represents what we call a \"Regularization\" of the function or a \"Penalty Term\" The purpose of $\\Omega(w)$ is to help us prevent the (otherwise complex) model from being overly complicated, by penalizing this complexity. There are many ways to do this that we will see later on, but one common way to do this for linear models is to penalize the **total weight** that you allow all of the $w_i$ to have. Specifically how one calculates this total weight turns out to matter a lot, and we shall see it return in future weeks. But to get us started in un-packing how to do this, we first need to talk about what a [Norm](https://en.wikipedia.org/wiki/Norm_(mathematics)) is, how it relates to Linear Regression weights, and how it helps us perform Regularization.\n",
    "\n",
    "### Norms and their relationship to Regularization\n",
    "A Norm is a concept in mathematics that allows us to essentially measure length or size, typically of vectors. Any time you have tried to compute the distance between two points in space (say, by using the Pythagorean Theorem), or the magnitude of an applied Force vector, you have been using a Norm -- most likely the Euclidean Norm or Euclidean Distance. For example, for a vector $\\mathbf{x}$ with $n$ dimensions, the Euclidean Norm looks like this:\n",
    "$$\n",
    "||\\mathbf{x}||_2 = \\sqrt{ x_1^2 + x_2^2 + \\cdots x_n^2 }\n",
    "$$\n",
    "If you have ever had to compute the total Force Magnitude given its x and y components (for example, in Statics class), you have used the Euclidean Norm to do so. In that context, it served to take multiple components of a Force aggregate them in such a way as to tell you something about the **total force** -- by analogy, we will do the same thing here with linear regression, where each weight is like a component and we can use the Euclidean Norm to compute the total weight.\n",
    "\n",
    "While Euclidean Norms may be quite useful or familiar to Engineers, it turns out that they are a special case of a much wider *family* of Norms called [*p-norms*](https://en.wikipedia.org/wiki/Lp_space#The_p-norm_in_finite_dimensions), which are defined as:\n",
    "$$\n",
    "||\\mathbf{x}||_p = \\left(|x_1|^p + |x_2|^p+\\cdots + |x_n|^p\\right)^{1/p} = \\left(\\sum_{i=1}^n \\left| x_i \\right|^p \\right)^{1/p}\n",
    "$$\n",
    "\n",
    "Specifically, the Euclidean Norm is called the L2-norm, or sometimes just the 2-norm. To see why this is, just set $p=2$ in the above, and note how it corresponds to the Euclidean Norm that we all know and love. So, by setting $p$ to a number between $0$ and $\\infty$, we can modify what the *total weight* means, and setting $p=2$ is the setting which we are all most familiar with. To get a visual sense of how norms vary, see below, which visualizes a line of \"circle\" of radius 1, but where the length of the line is determined by the p-norm. You will see that when p=2 this corresponds to what we are familiar with, but when p goes up or down things change.\n",
    "\n",
    "![illustrations of p-Norms](2D_unit_balls.png \"p-Norms\")\n",
    "\n",
    "For today, we will just focus on the L2-Norm, however we will revist norms again next week where we will see how changing the one we are using can have positive or negative effects in certain circumstances. \n",
    "\n",
    "For today's purpose, we will use the L2-Norm to help us penalize having linear regression models with really large weights, by essentially putting a cost on the total weight of the weight vector, where the total is measured by the L2-Norm. That is:\n",
    "$$\n",
    "Loss = \\sum_{n=1}^{N}||y-w\\cdot x||^2 + \\alpha \\cdot ||w||^2\n",
    "$$\n",
    "Where $\\alpha$ is the price we pay for including more weight in the linear model. If it reduces our error cost enough to offset the cost of the increased weight, then that may be worth it to us. Otherwise, we would err on the side of using less weight overall.\n",
    "\n",
    "This Regularization (i.e., increasing $\\alpha$) essentially allows you to trade off bias and variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Ridge Regression\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# alpha determines how much of \n",
    "# a penalty the weights incur\n",
    "alphas = [0, 1e-20, 1e-10, 1e-7, 1e-5, 1, 10, 100]\n",
    "\n",
    "# For the below example, let's\n",
    "# just consider a 15-degree polynomial\n",
    "d=15\n",
    "np.random.seed(100)\n",
    "\n",
    "for a in alphas:\n",
    "    plt.figure(figsize=(7, 7))\n",
    "    polynomial_features = PolynomialFeatures(degree=d,\n",
    "                                             include_bias=False)\n",
    "    #linear_regression = LinearRegression() #<- Note difference with next line\n",
    "    linear_regression = Ridge(alpha=a)\n",
    "    pipeline = Pipeline([(\"polynomial_features\", polynomial_features),\n",
    "                         (\"linear_regression\", linear_regression)])\n",
    "    # Fit model\n",
    "    pipeline.fit(X[:, np.newaxis], y)\n",
    "    # Get Training Accuracy\n",
    "    score = pipeline.score(X[:, np.newaxis],y)\n",
    "\n",
    "    # Plot things\n",
    "    X_plot = np.linspace(0, 1, 100)\n",
    "    plt.plot(X_plot, pipeline.predict(X_plot[:, np.newaxis]), label=\"Model\")\n",
    "    plt.plot(X_plot, true_fun(X_plot), '--',label=\"True function\")\n",
    "    plt.scatter(X, y, label=\"Samples\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.xlim((0, 1))\n",
    "    plt.ylim((-2, 2))\n",
    "    plt.legend(loc=\"best\")\n",
    "    \n",
    "    plt.title(\"Degree {}, Alpha {}\\nTrain score = {:.3f}\".format(\n",
    "        d, a, score))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Can we evaluate this more rigorously?\n",
    "Yes, we can use data we have not seen yet to get an estimate of the generalization error. One popular way to do this is through Cross-Validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's split the data into training and test data:\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at what the above has actually done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('X_train\\n',X_train,'\\n')\n",
    "print('X_test\\n',X_test,'\\n')\n",
    "print('y_train\\n',y_train,'\\n')\n",
    "print('y_test\\n',y_test,'\\n')\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.plot(X_plot, true_fun(X_plot), '--',label=\"True function\")\n",
    "# plot the training and testing points in colors\n",
    "plt.scatter(X_train,y_train, label=\"Training data\")\n",
    "plt.scatter(X_test,y_test, label=\"Testing data\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key idea in cross validation is to test the model on data that was separate from the data you trained on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = [0, 1e-20, 1e-10, 1e-7, 1e-5, 1,10]\n",
    "d=15\n",
    "for a in alphas:\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    #plt.setp(ax, xticks=(), yticks=())\n",
    "    polynomial_features = PolynomialFeatures(degree=d,\n",
    "                                             include_bias=False)\n",
    "    #linear_regression = LinearRegression()\n",
    "    linear_regression = Ridge(alpha=a)\n",
    "    pipeline = Pipeline([(\"polynomial_features\", polynomial_features),\n",
    "                         (\"linear_regression\", linear_regression)])\n",
    "    #pipeline.fit(X[:, np.newaxis], y)\n",
    "    pipeline.fit(X_train[:, np.newaxis], y_train)\n",
    "    # Evaluate the models using crossvalidation\n",
    "    #scores = cross_validation.cross_val_score(pipeline,\n",
    "    #    X[:, np.newaxis], y, scoring=\"mean_squared_error\", cv=10)\n",
    "    \n",
    "    testing_score = pipeline.score(X_test[:, np.newaxis],y_test)\n",
    "    training_score = pipeline.score(X_train[:, np.newaxis],y_train)\n",
    "\n",
    "    X_plot = np.linspace(0, 1, 100)\n",
    "    plt.plot(X_plot, pipeline.predict(X_plot[:, np.newaxis]), label=\"Model\")\n",
    "    plt.plot(X_plot, true_fun(X_plot), '--',label=\"True function\")\n",
    "    plt.scatter(X, y, label=\"Samples\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.xlim((0, 1))\n",
    "    plt.ylim((-2, 2))\n",
    "    plt.legend(loc=\"best\")\n",
    "    \n",
    "    plt.title(\"Degree {}, Alpha {}\\nTest score = {:.3f}\\nTraining score = {:.3f}\".format(\n",
    "        d, a, testing_score,training_score))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
