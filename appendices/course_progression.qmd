# Course Lecture Progression

This section describes an example progression through the course material based on my "Machine Learning for Mechanical Engineering" course at ETHZ. It assumes two lecture+exercise sessions twice a week, for a duration of 1 hour and 45 minutes each with a 5-10 minutes break in the middle of each session. This provides a sample of how you might work through the content in this book, and also acts as a reference to the students. My course is structured such that lectures and exercises occur in the same session, often alternating between lecture and in-class demonstrations or exercises, and this is frequently reflected in each of the book chapters. In class, for time reasons, I may skip some of the longer derivations in the book, since these can be effectively studied on their own.

## Part 0: Review

### Lecture 1: Course Introduction and Review of ML Basics
- Overview the course structure and syllabus
- Review several basics that should have been covered in the prior Stochastics and Machine Learning course
    - Cross Validation
    - Plotting/Diagnostics of ML models
    - Defining Notation for Linear models and subsequent lectures
- Example of how to use a Jupyter Notebook in class -- Linear Regression and Stochastic Gradient Descent
- (Re-)Introduction to Coding and Tooling basics to help with the rest of the course, such as Editors, Colab, Version Control, Basic Debugging

### Lecture 2: Automatic Differentiation and Taking Derivatives
- Read [Taking Derivatives](../part1/taking_derivatives.qmd)
- In-Class example of Forward and Reverse AD on a simple function
- In-Class example of Implicit Differentiation
- In-Class example with JVPs for computing some example properties of Linear Models, for example, the Fisher Information Matrix.

### Lecture 3: Review of Probabilistic Models
- Read @sec-reviewprobability of [Probabilistic Models](../part2/probabilistic_models.qmd), since this reviews the information from the prior course. We will revisit the later sections in a later lecture.
- In-Class exercise deriving the MLE for various common distributions

### Lecture 4: Review of Neural Network Models
- Read [Review of Neural Networks](../part2/review_NNs.qmd)
- In 
